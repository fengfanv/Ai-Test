#均方误差
import numpy as np
def mean_squared_error(y,t):
    return 0.5*np.sum((y-t)**2)

#设数字2，为正解，为正确答案
t = [0,0,1,0,0,0,0,0,0,0]#监督数据，这种将正确值标为1，其它值标为0的形式，叫one-hot模式

#例1，输出的y，数字2概率最高，概率是0.6
y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]#神经网络输出的y，这个数据值是由softmax函数输出的

print(mean_squared_error(np.array(y),np.array(t)))#0.09750000000000003

#例2，输出的y，数字7概率最高，概率是0.6
y2 = [0.1,0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]
print(mean_squared_error(np.array(y2),np.array(t)))#0.5975

#实验显示，第一个例子y的损失函数数值更小，和监督数据之间的误差更小，也就是说均方误差显示第一个例子y的输出结果与监督数据更加吻合




